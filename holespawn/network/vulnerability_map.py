"""
Synthesize network analysis + node profiles into a cohesive network vulnerability report (network_report.md).
v2.1: Accepts list[NodeProfile], builds Profiled Node Summaries, instructs LLM to use profile data.
"""

import json
import logging
from typing import Any

from holespawn.cost_tracker import CostTracker
from holespawn.llm import call_llm

from .graph_analysis import NetworkAnalysis, network_analysis_to_dict
from .node_profiler import NodeProfile

logger = logging.getLogger(__name__)

COMMUNITY_THEME_PROMPT = """Here are the members of a community in a social network:
Usernames: {usernames}
Profiled members (condensed): {profiled_summaries}

In 2-3 sentences, describe: what theme or interest unites this community? What is their collective character? What topics do they engage with? Reply with only the description, no preamble."""


def extract_community_themes(
    analysis: NetworkAnalysis,
    node_profiles: list[NodeProfile],
    *,
    tracker: CostTracker | None = None,
    provider: str | None = None,
    model: str | None = None,
    calls_per_minute: int = 20,
) -> None:
    """
    One LLM call per community: add themes and description to analysis.community_metrics.
    Mutates analysis.community_metrics[cid]["themes"] and ["description"].
    """
    from holespawn.llm import call_llm

    profiles_by_username = {p.username: p for p in node_profiles}
    for cid, members in analysis.communities.items():
        usernames = members[:30]
        profiled_in_c = [p for p in node_profiles if p.community_id == cid]
        profiled_summaries = ""
        if profiled_in_c:
            parts = []
            for p in profiled_in_c[:5]:
                bullets = _condense_profile_to_bullets(p.psychological_profile, max_bullets=4)
                parts.append(f"@{p.username}: " + "; ".join(bullets) + f" (role: {p.information_role})")
            profiled_summaries = "\n".join(parts)
        else:
            profiled_summaries = "No profiled members in this community."
        try:
            raw = call_llm(
                "You are a concise analyst. Reply with only the requested description, no preamble.",
                COMMUNITY_THEME_PROMPT.format(usernames=", ".join(usernames), profiled_summaries=profiled_summaries),
                provider_override=provider,
                model_override=model,
                max_tokens=256,
                operation="network_community_theme",
                tracker=tracker,
                calls_per_minute=calls_per_minute,
            )
            desc = (raw or "").strip()[:500]
            analysis.community_metrics[cid]["description"] = desc
            analysis.community_metrics[cid]["themes"] = []  # could parse keywords; keep simple
        except Exception as e:
            logger.warning("Community theme extraction failed for community %s: %s", cid, e)
            analysis.community_metrics[cid]["description"] = ""
            analysis.community_metrics[cid]["themes"] = []

VULNERABILITY_MAP_SYSTEM = """You are an analyst producing a **network vulnerability map** from the exact data provided.

CRITICAL: Use ONLY usernames, metrics, and counts that appear in the data below. Do NOT invent usernames, connection counts, roles, or community descriptions. If the data shows one community, say "single community" or "star topology"; do NOT invent multiple communities or bridge nodes. If a section has no data (e.g. no key node profiles), say "No data provided" or summarize only what is present.

You receive:
1. Network topology (nodes, edges, communities, density).
2. Profiled Node Summaries: for each profiled node, psychological profile bullets, approach vectors, cascade potential, resistance factors, strategic value.
3. Lists of bridge nodes, amplifiers, gatekeepers, vulnerable entry points, influence paths.

When generating the report:
- In "Optimal entry points": reference each node's specific psychological approach vectors, not just their graph position. Explain WHAT to say to them and WHY it would work based on their profile.
- In "Propagation playbook": use cascade_potential data from the node profiles to map concrete propagation sequences. Name specific nodes at each step.
- In "Resistance map": use resistance_factors from node profiles. Name specific resistant nodes and their specific objections/defenses.
- In "Community breakdown": use the profiled nodes within each community to characterize the community's psychological texture, not just its topology.

Produce a markdown report with exactly these sections (use these headers). Be evidence-based: every @username and every number must come from the data.

## Network topology summary
- State the exact node count, edge count, density, and number of communities from the data. One short paragraph. If there is only one community, describe it as a single community (e.g. star around one hub); do not invent sub-communities.

## Community breakdown
For each community ID that appears in the data: key members (usernames from the data only), size, and—using profiled nodes in that community—describe the community's psychological character and themes.

## Optimal entry points
List only usernames that appear in the bridge_nodes, vulnerable_entry_points, or amplifiers data. For EACH: use their approach_vectors and psychological profile to explain WHAT message or approach would work and WHY. Maximum 10 entries.

## Propagation playbook
Use influence_paths and cascade_potential from node profiles. Step-by-step: which node first, what approach, expected cascade (reach/hops/communities), then which node next. Name specific nodes.

## Amplification strategy
Reference only usernames from the amplifiers/bridge lists. Use their information_role and approach vectors. Do not invent sequences.

## Resistance map
Use resistance_factors from the Profiled Node Summaries. Name specific nodes and their specific objections or defenses. Where will influence be blocked?

## Cross-community bridges
If the data shows only one community, say "Single community; no cross-community bridges." Otherwise describe only bridge nodes that appear in the data.

Do not add preamble. Output only the markdown document."""


def _condense_profile_to_bullets(profile_dict: dict[str, Any], max_bullets: int = 5) -> list[str]:
    """Extract 3-5 bullet points from psychological_profile dict."""
    bullets = []
    if profile_dict.get("specific_interests"):
        bullets.append("Interests: " + ", ".join(profile_dict["specific_interests"][:6]))
    if profile_dict.get("obsessions"):
        bullets.append("Obsessions: " + ", ".join(profile_dict["obsessions"][:5]))
    if profile_dict.get("communication_style"):
        bullets.append("Style: " + str(profile_dict["communication_style"])[:120])
    if profile_dict.get("sentiment_compound") is not None:
        bullets.append(f"Sentiment: {profile_dict['sentiment_compound']:.2f}")
    if profile_dict.get("sample_phrases"):
        bullets.append("Sample phrases: " + ", ".join(profile_dict["sample_phrases"][:3]))
    if profile_dict.get("themes"):
        flat = [t for theme in profile_dict["themes"] for t in (theme if isinstance(theme, list) else [theme])]
        bullets.append("Themes: " + ", ".join(str(x) for x in flat[:5]))
    return bullets[:max_bullets]


def _build_profiled_summaries_section(profiled_nodes: list[NodeProfile]) -> str:
    """Build the Profiled Node Summaries section for the LLM prompt."""
    lines = ["## Profiled Node Summaries", ""]
    for p in profiled_nodes[:25]:
        bullets = _condense_profile_to_bullets(p.psychological_profile)
        profile_blurb = "\n".join(f"- {b}" for b in bullets) if bullets else "No summary available"
        reach = p.cascade_potential.get("estimated_reach", 0)
        hops = p.cascade_potential.get("hops", 0)
        comms = p.cascade_potential.get("communities_affected", [])
        lines.append(f"### @{p.username} — {p.role} in Community {p.community_id}")
        lines.append(f"Strategic value: {p.strategic_value_score}/10")
        lines.append(f"Information role: {p.information_role}")
        lines.append("Psychological profile summary:")
        lines.append(profile_blurb)
        lines.append("Approach vectors: " + "; ".join(p.approach_vectors) if p.approach_vectors else "Approach vectors: (none)")
        lines.append(f"Cascade potential: Reaches ~{reach} nodes across {comms} in {hops} hops")
        lines.append("Resistance factors: " + "; ".join(p.resistance_factors) if p.resistance_factors else "Resistance factors: (none)")
        lines.append("")
    return "\n".join(lines)


def generate_network_report(
    analysis: NetworkAnalysis,
    node_profiles: list[NodeProfile],
    target_username: str,
    *,
    tracker: CostTracker | None = None,
    provider: str | None = None,
    model: str | None = None,
    calls_per_minute: int = 20,
) -> str:
    """
    Generate network_report.md content from NetworkAnalysis and profiled nodes.
    Uses one LLM call to synthesize topology + communities + Profiled Node Summaries + entry points + playbook + resistance.
    """
    data = network_analysis_to_dict(analysis)
    density = (data.get("sanity_check") or {}).get("density", 0)
    parts = [
        "## Topology",
        f"Target: @{target_username.strip().lstrip('@')}",
        f"Nodes: {len(data['nodes'])}, Edges: {len(data['edges'])}, Density: {density}",
        f"Communities: {len(data['communities'])}",
        "Sanity: " + json.dumps(data.get("sanity_check") or {}, indent=2),
        "",
        "## Community metrics (per-community size, density, hub, bridge count, themes if any)",
        json.dumps(data.get("community_metrics") or {}, indent=2),
        "",
        "## Community profiles",
        json.dumps(data["community_profiles"], indent=2),
        "",
        "## Bridge nodes (top 15)",
        json.dumps(data["bridge_nodes"][:15], indent=2),
        "",
        "## Amplifiers (top 10)",
        json.dumps(data["amplifiers"][:10], indent=2),
        "",
        "## Gatekeepers (sample)",
        json.dumps(data["gatekeepers"][:15], indent=2),
        "",
        "## Vulnerable entry points",
        json.dumps(data["vulnerable_entry_points"][:15], indent=2),
        "",
        "## Influence paths (target -> key nodes)",
        json.dumps(data["influence_paths"][:10], indent=2),
        "",
        _build_profiled_summaries_section(node_profiles),
        "",
    ]
    user_content = "\n".join(parts)
    raw = call_llm(
        VULNERABILITY_MAP_SYSTEM,
        user_content,
        provider_override=provider,
        model_override=model,
        max_tokens=4096,
        operation="network_vulnerability_map",
        tracker=tracker,
        calls_per_minute=calls_per_minute,
    )
    return raw.strip()
