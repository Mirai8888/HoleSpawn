"""
Network vulnerability surface analysis: fragmentation, single points of failure,
community cohesion, and attack surface mapping.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any

import networkx as nx

logger = logging.getLogger(__name__)

try:
    from networkx.algorithms.community import greedy_modularity_communities
except ImportError:
    from networkx.algorithms.community.modularity_max import greedy_modularity_communities


@dataclass
class FragmentationResult:
    """Result of removing a single node and measuring network split."""
    node: str
    components_after: int
    largest_component_size: int
    fragmentation_ratio: float  # 1 - (largest_component / total)
    isolated_nodes: int

    def to_dict(self) -> dict:
        return {
            "node": self.node,
            "components_after": self.components_after,
            "largest_component_size": self.largest_component_size,
            "fragmentation_ratio": round(self.fragmentation_ratio, 4),
            "isolated_nodes": self.isolated_nodes,
        }


@dataclass
class CohesionScore:
    """Community cohesion metrics for a single cluster."""
    community_id: int
    size: int
    density: float
    avg_clustering: float
    internal_edges: int
    external_edges: int
    cohesion: float  # internal_edges / (internal + external)

    def to_dict(self) -> dict:
        return {
            "community_id": self.community_id,
            "size": self.size,
            "density": round(self.density, 4),
            "avg_clustering": round(self.avg_clustering, 4),
            "internal_edges": self.internal_edges,
            "external_edges": self.external_edges,
            "cohesion": round(self.cohesion, 4),
        }


@dataclass
class VulnerabilityReport:
    """Full vulnerability analysis result."""
    fragmentation: list[FragmentationResult] = field(default_factory=list)
    single_points_of_failure: list[dict[str, Any]] = field(default_factory=list)
    community_cohesion: list[CohesionScore] = field(default_factory=list)
    attack_surfaces: list[dict[str, Any]] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "fragmentation": [f.to_dict() for f in self.fragmentation],
            "single_points_of_failure": self.single_points_of_failure,
            "community_cohesion": [c.to_dict() for c in self.community_cohesion],
            "attack_surfaces": self.attack_surfaces,
        }


def analyze_fragmentation(G: nx.DiGraph) -> list[FragmentationResult]:
    """
    For each node, simulate removal and measure how the network fragments.

    Uses the undirected projection for connectivity analysis.
    Returns results sorted by fragmentation_ratio descending.
    """
    U = G.to_undirected()
    n_total = U.number_of_nodes()
    if n_total < 2:
        return []

    results = []
    # Only test nodes with betweenness > 0 or degree > 1 to save compute
    betweenness = nx.betweenness_centrality(U)
    candidates = [n for n in U.nodes() if betweenness.get(n, 0) > 0 or U.degree(n) > 1]

    for node in candidates:
        H = U.copy()
        H.remove_node(node)
        components = list(nx.connected_components(H))
        n_remaining = n_total - 1
        largest = max(len(c) for c in components) if components else 0
        isolated = sum(1 for c in components if len(c) == 1)
        frag_ratio = 1.0 - (largest / n_remaining) if n_remaining > 0 else 0.0

        results.append(FragmentationResult(
            node=node,
            components_after=len(components),
            largest_component_size=largest,
            fragmentation_ratio=frag_ratio,
            isolated_nodes=isolated,
        ))

    results.sort(key=lambda r: r.fragmentation_ratio, reverse=True)
    return results


def find_single_points_of_failure(G: nx.DiGraph) -> list[dict[str, Any]]:
    """
    Identify nodes whose removal disconnects the network or drastically
    reduces reachability. These are consensus bottlenecks.

    Returns nodes where removal increases connected components by >1.
    """
    U = G.to_undirected()
    # Articulation points are exact single points of failure
    try:
        artic = list(nx.articulation_points(U))
    except Exception:
        return []

    betweenness = nx.betweenness_centrality(G, weight="weight")
    degree = dict(G.degree())

    spofs = []
    for node in artic:
        spofs.append({
            "node": node,
            "betweenness": round(betweenness.get(node, 0), 4),
            "degree": degree.get(node, 0),
            "type": "articulation_point",
        })

    spofs.sort(key=lambda x: x["betweenness"], reverse=True)
    return spofs


def compute_community_cohesion(G: nx.DiGraph) -> list[CohesionScore]:
    """
    Compute cohesion metrics for each detected community.

    Cohesion = internal_edges / (internal + external edges).
    High cohesion = tightly coupled cluster. Low = loosely bound.
    """
    U = G.to_undirected()
    if U.number_of_nodes() < 3:
        return []

    try:
        communities = list(greedy_modularity_communities(U))
    except Exception:
        return []

    node_community: dict[str, int] = {}
    for cid, members in enumerate(communities):
        for m in members:
            node_community[m] = cid

    scores = []
    for cid, members in enumerate(communities):
        member_set = set(members)
        subgraph = U.subgraph(member_set)
        internal = subgraph.number_of_edges()

        # Count external edges
        external = 0
        for node in member_set:
            for nbr in U.neighbors(node):
                if nbr not in member_set:
                    external += 1

        total = internal + external
        cohesion = internal / total if total > 0 else 1.0

        density = nx.density(subgraph) if len(member_set) > 1 else 0.0
        avg_clust = nx.average_clustering(subgraph) if len(member_set) > 1 else 0.0

        scores.append(CohesionScore(
            community_id=cid,
            size=len(member_set),
            density=density,
            avg_clustering=avg_clust,
            internal_edges=internal,
            external_edges=external,
            cohesion=cohesion,
        ))

    scores.sort(key=lambda s: s.cohesion, reverse=True)
    return scores


def map_attack_surface(
    G: nx.DiGraph,
    target_fragmentation: float = 0.5,
    max_nodes: int = 20,
) -> list[dict[str, Any]]:
    """
    Find the minimum node set whose removal fragments at least
    target_fragmentation proportion of the network.

    Uses a greedy approach: iteratively remove the highest-betweenness node,
    recalculate, repeat until fragmentation target is reached.

    Args:
        G: The network graph.
        target_fragmentation: Fraction of network to fragment (0.0-1.0).
        max_nodes: Maximum nodes to include in attack set.

    Returns:
        List of dicts with node removal order and cumulative fragmentation.
    """
    U = G.to_undirected().copy()
    n_total = U.number_of_nodes()
    if n_total < 3:
        return []

    removal_order: list[dict[str, Any]] = []
    removed = set()

    for step in range(min(max_nodes, n_total - 1)):
        if U.number_of_nodes() < 2:
            break

        betweenness = nx.betweenness_centrality(U)
        if not betweenness:
            break

        target_node = max(betweenness, key=betweenness.get)
        U.remove_node(target_node)
        removed.add(target_node)

        components = list(nx.connected_components(U))
        largest = max(len(c) for c in components) if components else 0
        n_remaining = n_total - len(removed)
        frag = 1.0 - (largest / n_remaining) if n_remaining > 0 else 1.0

        removal_order.append({
            "step": step + 1,
            "node_removed": target_node,
            "betweenness_at_removal": round(betweenness[target_node], 4),
            "components_after": len(components),
            "cumulative_fragmentation": round(frag, 4),
            "nodes_removed_total": len(removed),
        })

        if frag >= target_fragmentation:
            break

    return removal_order


def analyze_vulnerability(
    G: nx.DiGraph,
    target_fragmentation: float = 0.5,
) -> VulnerabilityReport:
    """
    Run full vulnerability analysis on a directed graph.

    Args:
        G: NetworkX DiGraph with weighted edges.
        target_fragmentation: Target for attack surface mapping.

    Returns:
        VulnerabilityReport with all analysis results.
    """
    return VulnerabilityReport(
        fragmentation=analyze_fragmentation(G),
        single_points_of_failure=find_single_points_of_failure(G),
        community_cohesion=compute_community_cohesion(G),
        attack_surfaces=map_attack_surface(G, target_fragmentation),
    )
